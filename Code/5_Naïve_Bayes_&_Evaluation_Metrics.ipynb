{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "5 NaÃ¯ve Bayes & Evaluation Metrics",
      "provenance": [],
      "authorship_tag": "ABX9TyMSwEdUlHMo16GwnFny7Bl1"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "RYuqpmBl94oO"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.utils.np_utils import to_categorical\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "import pandas as pd\n",
        "import sys, os, re, csv, codecs\n",
        "from sklearn.feature_extraction.text import TfidfTransformer\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "import math\n",
        "import random\n",
        "from collections import defaultdict\n",
        "from pprint import pprint\n",
        "# Prevent future/deprecation warnings from showing in output\n",
        "import warnings\n",
        "warnings.filterwarnings(action='ignore')\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from imblearn.over_sampling import SMOTE\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score, classification_report, confusion_matrix\n",
        "from sklearn.metrics import roc_auc_score\n",
        "from itertools import product\n",
        "import numpy"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q5UUiyaD97Uh"
      },
      "source": [
        "data =pd.read_csv('file path', encoding='utf-8', usecols=['col1', 'col2'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8hm9_XAF4w5m"
      },
      "source": [
        "data.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qk82Vfd843QI"
      },
      "source": [
        "data.sentiment.value_counts()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nUTmTly599sl"
      },
      "source": [
        "X = data.full_text\n",
        "y = data.sentiment\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
        "X_train.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YKHOtmg-5Ees"
      },
      "source": [
        "len(X_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C6HZ1BH-5Fwm"
      },
      "source": [
        "y_train.value_counts()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ag-Lv5Am5KVR"
      },
      "source": [
        "y_test.value_counts()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z-ymDCg15OoN"
      },
      "source": [
        "# Removing stop words\n",
        "def get_stop_words(path):\n",
        "    #\"stop_words.txt\"\n",
        "    stop_words = []\n",
        "    with codecs.open(path, \"r\", encoding=\"utf-8\", errors=\"ignore\") as myfile:\n",
        "        stop_words = myfile.readlines()\n",
        "    stop_words = [word.strip() for word in stop_words]\n",
        "    return stop_words\n",
        "stop_words = get_stop_words('/content/stop_words_arabic.txt')\n",
        "\n",
        "from sklearn.pipeline import Pipeline\n",
        "text_clf = Pipeline([('vect', CountVectorizer(stop_words=stop_words)), ('tfidf', TfidfTransformer()), \n",
        "                     ('clf', MultinomialNB())])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BEZ-cCxY9_0c"
      },
      "source": [
        "vect = CountVectorizer(max_features=1000, binary=True)\n",
        "X_train_vect = vect.fit_transform(X_train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kKNDipvh-FVm"
      },
      "source": [
        "sm = SMOTE()\n",
        "X_train_res, y_train_res = sm.fit_sample(X_train_vect, y_train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_xUg7tb--HZm"
      },
      "source": [
        "unique, counts = np.unique(y_train_res, return_counts=True)\n",
        "print(list(zip(unique, counts)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OdoZJBWe-IFM"
      },
      "source": [
        "#This is the fit score, and not the actual accuracy score\n",
        "nb = MultinomialNB()\n",
        "nb.fit(X_train_res, y_train_res)\n",
        "nb.score(X_train_res, y_train_res)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uP-aUpoV-Lw7"
      },
      "source": [
        "X_test_vect = vect.transform(X_test)\n",
        "y_pred = nb.predict(X_test_vect)\n",
        "y_pred"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "54vhFtnF-N0E"
      },
      "source": [
        "clf= MultinomialNB()\n",
        "clf.fit(X_train_res, y_train_res)\n",
        "\n",
        "score = clf.score(X_train_res, y_train_res)\n",
        "print(\"score of Naive Bayes algo is :\" , score)\n",
        "\n",
        "y_pred = clf.predict(X_test_vect)\n",
        "print(confusion_matrix(y_test,y_pred))\n",
        "\n",
        "print(\"Precision Score : \",precision_score(y_test, y_pred, \n",
        "                                           average='micro'))\n",
        "print(\"Recall Score : \",recall_score(y_test, y_pred, \n",
        "                                           average='micro'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sprweUzl-OiS"
      },
      "source": [
        "print(confusion_matrix(y_test,y_pred))\n",
        "print(classification_report(y_test,y_pred))\n",
        "print(accuracy_score(y_test,y_pred))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "404-HKA4-QS-"
      },
      "source": [
        "def plot_confusion_matrix(cm, classes, title='Confusion matrix', cmap=plt.cm.Blues):\n",
        "    cm = cm.astype('float') / cm.sum(axis=1)[:, numpy.newaxis]\n",
        "    print(cm)\n",
        "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
        "    plt.title(title)\n",
        "    plt.colorbar()\n",
        "    tick_marks = numpy.arange(len(classes))\n",
        "    plt.xticks(tick_marks, classes, rotation=45)\n",
        "    plt.yticks(tick_marks, classes)\n",
        "    fmt = '.2f'\n",
        "    thresh = cm.max() / 2.\n",
        "    for i, j in product(range(cm.shape[0]), range(cm.shape[1])):\n",
        "        plt.text(j, i, format(cm[i, j], fmt), horizontalalignment=\"center\", color=\"white\" if cm[i, j] > thresh else \"black\")\n",
        "    plt.ylabel('True')\n",
        "    plt.xlabel('Predicted')\n",
        "    plt.tight_layout()\n",
        "    plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ec30f54K-SjR"
      },
      "source": [
        "class_labels = ['Positive', 'Negative', 'Neutral']\n",
        "cm = confusion_matrix(y_test,y_pred).T\n",
        "plot_confusion_matrix(cm, classes = class_labels)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xC6TihSYdzpI"
      },
      "source": [
        "**Evaluation Metrics for Classification**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cD9R_0Am-WAO"
      },
      "source": [
        "mat = confusion_matrix(y_test,y_pred)\n",
        "# Confusion Matrix\n",
        "print(mat)\n",
        "# Classification Report\n",
        "print(classification_report(y_test,y_pred))\n",
        "sns.heatmap(mat.T, square=True, annot=True, fmt='d', cbar=False, xticklabels = True, yticklabels = True)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}
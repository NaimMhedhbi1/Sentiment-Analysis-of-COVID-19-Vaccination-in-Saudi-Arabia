{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "8-Data_Cleaning.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyM8ePIYVoS2iPjGjDN44Wfb"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iCda_7rUwmds"
      },
      "source": [
        "**Import the required libraries**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YzeTeN_3cUAz"
      },
      "source": [
        "pip install pyarabic"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VMt_SqYDig8V"
      },
      "source": [
        "#-- not all the imported lib are used in this notebook --#\n",
        "from textblob import TextBlob\n",
        "from wordcloud import WordCloud\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import re\n",
        "import matplotlib.pyplot as plt\n",
        "plt.style.use('fivethirtyeight')\n",
        "from nltk.corpus import stopwords\n",
        "import sys\n",
        "import nltk\n",
        "from nltk.tokenize import word_tokenize\n",
        "#Import arabic libraries\n",
        "import pyarabic.araby as araby\n",
        "import pyarabic.number as number\n",
        "import argparse"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GPIVPDdI7qyR"
      },
      "source": [
        "#Part1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7x84AImCFXwx"
      },
      "source": [
        "1-Removing the dublicates"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LKsqpop9Ajtb"
      },
      "source": [
        "#df=pd.read_csv('/content/in-class8.csv',usecols=['date','username','name','tweet'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v1Hz45yLWw1y"
      },
      "source": [
        "df=pd.read_excel('/content/ALL.xlsx',usecols=['date','username','name','tweet','events'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "17fa28pgIaYx"
      },
      "source": [
        "#dublicates in tweet column\n",
        "df.tweet.duplicated().sum()#we can remove the \"sum\" to see what columns that are duplicated"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZRS0N5qoJp_T"
      },
      "source": [
        "df.duplicated().sum()#to see dublicates in general not only specific column "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JHchLKqrKNnP"
      },
      "source": [
        "df.loc[df.duplicated(keep='last'), :]# to see what are these columns - 'first' can also be changed to last depends on what cloumns you want to consider as first appeared or use False "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rvZohDdfM85i"
      },
      "source": [
        "#df.duplicated(subset=['tweet','name']).sum()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XCei9s86IoTV"
      },
      "source": [
        "#df.tweet.drop_duplicates(keep='first').shape # 'first' 'last' False"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UL_uoxeMA795"
      },
      "source": [
        "print(df[~df.duplicated(subset=['tweet'])]) # the ~ sign is to remove the dublicated fields! ,'name'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9l5_d_cTE07A"
      },
      "source": [
        "df[~df.duplicated(subset=['tweet'])].to_csv('8_dropduplicated.csv',index=False)#save the cleaned data"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DwadETInrpoN"
      },
      "source": [
        "2-Drop rows with certine value"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qZwnDNlXsJqi"
      },
      "source": [
        "df=pd.read_excel('/content/ALL_p3.xlsx',usecols=['date','username','name','tweet'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0hbNcKQaygN3"
      },
      "source": [
        "#Drop the row if the \"name\"  contains any keyword mentioned in \"searchfor\"\n",
        "searchfor = ['مدينة','دليل','غرفة','تأجير','بلدية','كلية','أنباء','موقع','منوعات','تعليم','مبادرة','وظيفة','مجمع','الأن','واتس','مشاهد','موجز','تحديث','وسم','الكرة','سناب','محافظة','إمارة','شركة','عكاظ','الاهرام','هاشتاق','اليوم','الجزائرية','المغربية','إجازة','اجازة','إدارة','رتويت','عناوين','إذاعة','channel','news','معهد','جامعة','مدرسة','حقائق','دليل','الوطن','اون لاين','محتوى','خطابة','اليمنية','السورية','الاردنية','الكويتية','الاماراتية','العربية','الدولية','الخليجية','شبكة','اونلاين','نيوز','صحيفة', 'جريدة' ,'قناة ','مجلة','جوال','القاهرة' ,'الالكترونية','مواعيد','حجوزات','حجز','أخبار','اخبار']\n",
        "data = df[~df.name.str.contains('|'.join(searchfor), na=False)]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gvDo6TCmR6xV"
      },
      "source": [
        "len(data)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DR1V_4dMefWh"
      },
      "source": [
        "data = df[~df.name.str.contains('|'.join(searchfor), na=False)].to_excel('drop1.xlsx')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gIXNyGgcSeqj"
      },
      "source": [
        "df=pd.read_excel('/content/drop1.xlsx',usecols=['date','username','name','tweet','events'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cw__d3BJ3-x2"
      },
      "source": [
        "#Drop the row if the \"name\"  contains any keyword from list1 except it has any keyword from list2 in \"tweet\" then keep it.\n",
        "List1 = ['_q8','🇶🇦','🇰🇼','Q8','uae','kuwait','leban','syri','qata','qtri','lib','yem','oman','Kuwaiti','egy','Egyp','egypt','q8','🇪🇬','rtarabic','🇧🇭','iraq','🇵🇸','online','🇦🇪']\n",
        "List2 = ['ksa','Saudi','السعودية','توكلنا','Tawakkalna','المملكة']\n",
        "data1=data[~data[\"name\"].astype(str).str.contains('|'.join(List1)) | data[\"tweet\"].astype(str).str.contains('|'.join(List2))]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-ytoGyhuTedm"
      },
      "source": [
        "len(data1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J-cp3JC3hsVI"
      },
      "source": [
        "#Drop the row if the \"username\"  contains any keyword from list1 except it has any keyword from list2 in \"tweet\" then keep it.\n",
        "List1 = ['_q8','q8','Q8','kw','uae','kuwait','leban','syri','qata','qtri','lib','yem','oman','Kuwaiti','egy','egypt','rtarabic','bh','iraq','online']\n",
        "List2 = ['ksa','Saudi','السعودية','توكلنا','Tawakkalna','المملكة']\n",
        "data2= data1[~data1[\"username\"].astype(str).str.contains('|'.join(List1)) | data1[\"tweet\"].astype(str).str.contains('|'.join(List2))]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HVE0_UYCTa0W"
      },
      "source": [
        "len(data2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GEsVVvcIhdpz"
      },
      "source": [
        "data2.to_excel('multipleq_clean_part3.xlsx')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_fNLVHSO7gQK"
      },
      "source": [
        "#Part2"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cSdw9MyHi1AZ"
      },
      "source": [
        "df=pd.read_excel('/content/ALL.xlsx', usecols=['date','tweet'])#Reading the data file and show only tweet column\n",
        "df.head()#show the file content\n",
        "#,'username','name'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bDKnndhVcZWD"
      },
      "source": [
        "#df.loc[df['tweet'].str.contains('@', case=False), 'tweet'] = '@username'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wzs-vEPZDmmp"
      },
      "source": [
        "Remove Dicritics and normalization "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rgIVDlHJjM4p"
      },
      "source": [
        "def normalize_arabic(text):\n",
        "    text = re.sub(\"[إأآ]\", \"ا\", text)\n",
        "    text = re.sub(\"ى\", \"ي\", text)\n",
        "    text = re.sub(\"ؤ\", \"و\", text)\n",
        "    text = re.sub(\"ئ\", \"ء\", text)\n",
        "    text = re.sub(\"ة\", \"ه\", text)\n",
        "    text = re.sub(\"گ\", \"ك\", text)\n",
        "    return text;"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Oe8lluP3jR6U"
      },
      "source": [
        "df[\"tweet\"]=df[\"tweet\"].apply(lambda x : normalize_arabic(x) )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V7h_VudwjgIQ"
      },
      "source": [
        "print(df)#no need but i like to see the result step by step!"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iWQry0W1jJ3S"
      },
      "source": [
        "\n",
        "\n",
        "arabic_diacritics = re.compile(\"\"\" ّ    | # Tashdid\n",
        "                             َ    | # Fatha\n",
        "                             ً    | # Tanwin Fath\n",
        "                             ُ    | # Damma\n",
        "                             ٌ    | # Tanwin Damm\n",
        "                             ِ    | # Kasra\n",
        "                             ٍ    | # Tanwin Kasr\n",
        "                             ْ    | # Sukun\n",
        "                             ـ     # Tatwil/Kashida\n",
        "                         \"\"\", re.VERBOSE)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "89HjIMqRjYPl"
      },
      "source": [
        "def remove_diacritics(text):\n",
        "    text = re.sub(arabic_diacritics,\"\", text)\n",
        "    return text;"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ID2fy3g1ja_B"
      },
      "source": [
        "  df[\"tweet\"]=df[\"tweet\"].apply(lambda x : remove_diacritics(x) )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I073LEQEklUx"
      },
      "source": [
        "df.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CsW2_mRbsJi2"
      },
      "source": [
        "# this code removes all words contains underscore from the dataset\n",
        "def filter_string(str):\n",
        "  a=[]\n",
        "  for i in str.split():\n",
        "        if \"_\" not in i:\n",
        "            a.append(i)\n",
        "  return ' '.join(a)\n",
        "\n",
        "df[\"tweet\"]=df[\"tweet\"].apply(lambda x : filter_string(x) )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9uDQghRPksw9"
      },
      "source": [
        "df.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z2a-JXtNw3UZ"
      },
      "source": [
        "\n",
        "\n",
        "> **clean data from:**\n",
        "\n",
        "\n",
        "* Numbers\n",
        "*Upper and lower case english letters\n",
        "*Newline "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xJbsuKKZbLuE"
      },
      "source": [
        "#arabic_numbers = '۰۱۲۳٤٥٦٧۸۹'\n",
        "def clean_tweets(text):\n",
        " \n",
        " text=re.sub(\"[0-9]\",\"\",text)#Remove Numbers\n",
        " text=re.sub(\"[a-zA-Z]\",\"\",text)#all english letters\n",
        " text=re.sub(\"_\",\" \",text) #Already take care of in the previous step!\n",
        " text=re.sub(\"\\n\",\"\",text)#remove newline\n",
        " #text=re.sub(\"[+arabic_numbers+]\",\"\",text)\n",
        " return text;\n",
        "\n",
        "#arabic_numbers = '۰۱۲۳٤٥٦٧۸۹'\n",
        "#df['tweet']= df['tweet'].str.replace(\"[\"+arabic_numbers+\"]\",'')\n",
        "#df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CV8Sb5kLcDxR"
      },
      "source": [
        "  df[\"tweet\"]=df[\"tweet\"].apply(lambda x : clean_tweets(x) )# save the result"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vlpVEnFwcLJC"
      },
      "source": [
        "  print(df)# show the result"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dt84xtckjvoW"
      },
      "source": [
        "df['tweet'] = df['tweet'].str.replace(r'\\W',\" \")#Remove Special \"Char\" after removing the diacritics to avoid deleteing the text contains diacritics\n",
        "print(df)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1qF58vkilBqo"
      },
      "source": [
        "df['tweet'] = df['tweet'].str.replace(r' +',\" \") #Remove more than one space betweeen the words\n",
        "print(df)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4jv5B9ycmkyp"
      },
      "source": [
        "#df=pd.read_csv('/content/processed_new_vaccine.csv')\n",
        "df.to_excel(\"/content/ALL_clean.xlsx\")# save in excel format"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8-ou_zATFg72"
      },
      "source": [
        "**Data Preprocessing**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2Wmvd6TRC--5"
      },
      "source": [
        "df=pd.read_excel('/content/all datacollected.xlsx', usecols=['sentiment','tweet'])\n",
        "df.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9Rpbyj1QDyh0"
      },
      "source": [
        "df['sentiment'] = df.sentiment.map({'neutral':2, 'negative':0, 'positive':1})\n",
        "print(df.shape)# to get the size\n",
        "df.head() "
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}